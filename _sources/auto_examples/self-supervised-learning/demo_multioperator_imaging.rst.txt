
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/self-supervised-learning/demo_multioperator_imaging.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_self-supervised-learning_demo_multioperator_imaging.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_self-supervised-learning_demo_multioperator_imaging.py:


Self-supervised learning from incomplete measurements of multiple operators.
====================================================================================================

This example shows you how to train a reconstruction network for an inpainting
inverse problem on a fully self-supervised way, i.e., using measurement data only.

The dataset consists of pairs :math:`(y_i,A_{g_i})` where :math:`y_i` are the measurements and :math:`A_{g_i}` is a
binary sampling operator out of :math:`G` (i.e., :math:`g_i\in \{1,\dots,G\}`).

This self-supervised learning approach is presented in `"Unsupervised Learning From Incomplete Measurements for
Inverse Problems" <https://openreview.net/pdf?id=aV9WSvM6N3>`_, and minimizes the loss function:

.. math::

    \mathcal{L}(\theta) = \sum_{i=1}^{N} \left\|A_{g_i} \hat{x}_{i,\theta} - y_i \right\|_2^2 + \sum_{s=1}^{G}
    \left\|\hat{x}_{i,\theta} - R_{\theta}(A_s\hat{x}_{i,\theta},A_s) \right\|_2^2

where :math:`R_{\theta}` is a reconstruction network with parameters :math:`\theta`, :math:`y_i` are the measurements,
:math:`A_s` is a binary sampling operator, and :math:`\hat{x}_{i,\theta} = R_{\theta}(y_i,A_{g_i})`.

.. GENERATED FROM PYTHON SOURCE LINES 23-33

.. code-block:: Python


    import deepinv as dinv
    from torch.utils.data import DataLoader
    import torch
    from pathlib import Path
    from torchvision import transforms
    from deepinv.models.utils import get_weights_url
    from deepinv.training_utils import train, test
    from torchvision import datasets








.. GENERATED FROM PYTHON SOURCE LINES 34-37

Setup paths for data loading and results.
---------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 37-50

.. code-block:: Python


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    DEG_DIR = BASE_DIR / "degradations"
    CKPT_DIR = BASE_DIR / "ckpts"

    # Set the global random seed from pytorch to ensure reproducibility of the example.
    torch.manual_seed(0)

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 51-55

Load base image datasets and degradation operators.
----------------------------------------------------------------------------------
In this example, we use the MNIST dataset for training and testing.


.. GENERATED FROM PYTHON SOURCE LINES 55-65

.. code-block:: Python


    transform = transforms.Compose([transforms.ToTensor()])

    train_base_dataset = datasets.MNIST(
        root="../datasets/", train=True, transform=transform, download=True
    )
    test_base_dataset = datasets.MNIST(
        root="../datasets/", train=False, transform=transform, download=True
    )








.. GENERATED FROM PYTHON SOURCE LINES 66-76

Generate a dataset of subsampled images and load it.
----------------------------------------------------------------------------------
We generate 10 different inpainting operators, each one with a different random mask.
If the :func:`deepinv.datasets.generate_dataset` receives a list of physics operators, it
generates a dataset for each operator and returns a list of paths to the generated datasets.

.. note::

  We only use 10 training images per operator to reduce the computational time of this example. You can use the whole
  dataset by setting ``n_images_max = None``.

.. GENERATED FROM PYTHON SOURCE LINES 76-114

.. code-block:: Python


    number_of_operators = 10

    # defined physics
    physics = [
        dinv.physics.Inpainting(mask=0.5, tensor_size=(1, 28, 28), device=device)
        for _ in range(number_of_operators)
    ]

    # Use parallel dataloader if using a GPU to reduce training time,
    # otherwise, as all computes are on CPU, use synchronous data loading.
    num_workers = 4 if torch.cuda.is_available() else 0
    n_images_max = (
        None if torch.cuda.is_available() else 50
    )  # number of images used for training (uses the whole dataset if you have a gpu)

    operation = "inpainting"
    my_dataset_name = "demo_multioperator_imaging"
    measurement_dir = DATA_DIR / "MNIST" / operation
    deepinv_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_base_dataset,
        test_dataset=test_base_dataset,
        physics=physics,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        test_datapoints=10,
        num_workers=num_workers,
        dataset_filename=str(my_dataset_name),
    )

    train_dataset = [
        dinv.datasets.HDF5Dataset(path=path, train=True) for path in deepinv_datasets_path
    ]
    test_dataset = [
        dinv.datasets.HDF5Dataset(path=path, train=False) for path in deepinv_datasets_path
    ]





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing train measurement vectors from base dataset of operator 1 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 397.87it/s]
    Computing test measurement vectors from base dataset of operator 1 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 985.50it/s]
    Computing train measurement vectors from base dataset of operator 2 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 520.71it/s]
    Computing test measurement vectors from base dataset of operator 2 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]
    Computing train measurement vectors from base dataset of operator 3 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 516.09it/s]
    Computing test measurement vectors from base dataset of operator 3 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 929.79it/s]
    Computing train measurement vectors from base dataset of operator 4 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 514.20it/s]
    Computing test measurement vectors from base dataset of operator 4 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 981.35it/s]
    Computing train measurement vectors from base dataset of operator 5 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 516.16it/s]
    Computing test measurement vectors from base dataset of operator 5 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 1011.89it/s]
    Computing train measurement vectors from base dataset of operator 6 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 521.03it/s]
    Computing test measurement vectors from base dataset of operator 6 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 1013.12it/s]
    Computing train measurement vectors from base dataset of operator 7 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 519.93it/s]
    Computing test measurement vectors from base dataset of operator 7 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 1015.57it/s]
    Computing train measurement vectors from base dataset of operator 8 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 518.71it/s]
    Computing test measurement vectors from base dataset of operator 8 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 991.80it/s]
    Computing train measurement vectors from base dataset of operator 9 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 520.45it/s]
    Computing test measurement vectors from base dataset of operator 9 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 1021.01it/s]
    Computing train measurement vectors from base dataset of operator 10 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 529.38it/s]
    Computing test measurement vectors from base dataset of operator 10 out of 10...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 988.29it/s]
    Dataset has been saved in measurements/MNIST/inpainting




.. GENERATED FROM PYTHON SOURCE LINES 115-120

Set up the reconstruction network
---------------------------------------------------------------

As a reconstruction network, we use a simple artifact removal network based on a U-Net.
The network is defined as a :math:`R_{\theta}(y,A)=\phi_{\theta}(A^{\top}y)` where :math:`\phi` is the U-Net.

.. GENERATED FROM PYTHON SOURCE LINES 120-127

.. code-block:: Python


    # Define the unfolded trainable model.
    model = dinv.models.ArtifactRemoval(
        backbone_net=dinv.models.UNet(in_channels=1, out_channels=1, scales=3)
    )
    model = model.to(device)








.. GENERATED FROM PYTHON SOURCE LINES 128-139

Set up the training parameters
--------------------------------------------
We choose a self-supervised training scheme with two losses: the measurement consistency loss (MC)
and the multi-operator imaging loss (MOI).
Necessary and sufficient conditions on the number of operators and measurements are described
`here <https://www.jmlr.org/papers/v24/22-0315.html>`_.

.. note::

      We use a pretrained model to reduce training time. You can get the same results by training from scratch
      for 100 epochs.

.. GENERATED FROM PYTHON SOURCE LINES 139-162

.. code-block:: Python


    epochs = 1
    learning_rate = 5e-4
    batch_size = 64 if torch.cuda.is_available() else 1

    # choose self-supervised training losses
    # generates 4 random rotations per image in the batch
    losses = [dinv.loss.MCLoss(), dinv.loss.MOILoss(physics)]

    # choose optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8) + 1)

    # start with a pretrained model to reduce training time
    file_name = "demo_moi_ckp_10.pth"
    url = get_weights_url(model_name="demo", file_name=file_name)
    ckpt = torch.hub.load_state_dict_from_url(
        url, map_location=lambda storage, loc: storage, file_name=file_name
    )
    # load a checkpoint to reduce training time
    model.load_state_dict(ckpt["state_dict"])
    optimizer.load_state_dict(ckpt["optimizer"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/demo/resolve/main/demo_moi_ckp_10.pth?download=true" to /home/runner/.cache/torch/hub/checkpoints/demo_moi_ckp_10.pth
      0%|          | 0.00/23.8M [00:00<?, ?B/s]      1%|▏         | 360k/23.8M [00:00<00:06, 3.67MB/s]     22%|██▏       | 5.34M/23.8M [00:00<00:00, 32.3MB/s]     64%|██████▍   | 15.2M/23.8M [00:00<00:00, 64.4MB/s]    100%|██████████| 23.8M/23.8M [00:00<00:00, 66.3MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 163-167

Train the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 167-197

.. code-block:: Python



    verbose = True  # print training information
    wandb_vis = False  # plot curves and images in Weight&Bias

    train_dataloader = [
        DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)
        for dataset in train_dataset
    ]
    test_dataloader = [
        DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)
        for dataset in test_dataset
    ]

    train(
        model=model,
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        epochs=epochs,
        scheduler=scheduler,
        losses=losses,
        physics=physics,
        optimizer=optimizer,
        device=device,
        save_path=str(CKPT_DIR / operation),
        verbose=verbose,
        wandb_vis=wandb_vis,
        ckp_interval=10,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 2069441 trainable parameters
      0%|          | 0/5 [00:00<?, ?it/s]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.00024, loss_moi=0.00206, total_loss=0.0023, train_psnr=20.4]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.000433, loss_moi=0.00137, total_loss=0.00181, train_psnr=21]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.000605, loss_moi=0.00279, total_loss=0.00339, train_psnr=20.9]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.000725, loss_moi=0.00398, total_loss=0.00471, train_psnr=20.3]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.00132, loss_moi=0.00417, total_loss=0.00549, train_psnr=20.3]     Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.00131, loss_moi=0.00381, total_loss=0.00512, train_psnr=20.7]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.00139, loss_moi=0.00418, total_loss=0.00557, train_psnr=20.3]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.00141, loss_moi=0.00411, total_loss=0.00552, train_psnr=20.2]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.00136, loss_moi=0.00391, total_loss=0.00528, train_psnr=20.3]    Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, eval_psnr=23.5, loss_mc=0.00134, loss_moi=0.00511, total_loss=0.00645, train_psnr=19.8]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00134, loss_moi=0.00511, total_loss=0.00645, train_psnr=19.8]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00134, loss_moi=0.00511, total_loss=0.00645, train_psnr=19.8]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.0014, loss_moi=0.00556, total_loss=0.00696, train_psnr=19.5]     Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00155, loss_moi=0.00547, total_loss=0.00701, train_psnr=19.6]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00161, loss_moi=0.00515, total_loss=0.00676, train_psnr=19.4]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00161, loss_moi=0.00511, total_loss=0.00672, train_psnr=19.4]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00167, loss_moi=0.00497, total_loss=0.00664, train_psnr=19.3]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00169, loss_moi=0.00499, total_loss=0.00668, train_psnr=19.5]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00177, loss_moi=0.00474, total_loss=0.00652, train_psnr=19.5]    Epoch 1:  20%|██        | 1/5 [00:00<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00181, loss_moi=0.00466, total_loss=0.00647, train_psnr=19.5]    Epoch 1:  20%|██        | 1/5 [00:01<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00175, loss_moi=0.0048, total_loss=0.00655, train_psnr=19.5]     Epoch 1:  20%|██        | 1/5 [00:01<00:02,  1.86it/s, eval_psnr=23.5, loss_mc=0.00174, loss_moi=0.00483, total_loss=0.00657, train_psnr=19.6]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00174, loss_moi=0.00483, total_loss=0.00657, train_psnr=19.6]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00174, loss_moi=0.00483, total_loss=0.00657, train_psnr=19.6]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00171, loss_moi=0.00493, total_loss=0.00665, train_psnr=19.6]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00177, loss_moi=0.00487, total_loss=0.00664, train_psnr=19.6]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.0018, loss_moi=0.00483, total_loss=0.00663, train_psnr=19.4]     Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00185, loss_moi=0.00477, total_loss=0.00662, train_psnr=19.4]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00189, loss_moi=0.00468, total_loss=0.00656, train_psnr=19.4]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00184, loss_moi=0.00484, total_loss=0.00669, train_psnr=19.3]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00181, loss_moi=0.00505, total_loss=0.00686, train_psnr=19.2]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00181, loss_moi=0.00497, total_loss=0.00679, train_psnr=19.2]    Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00182, loss_moi=0.00488, total_loss=0.0067, train_psnr=19.3]     Epoch 1:  40%|████      | 2/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00183, loss_moi=0.00496, total_loss=0.00679, train_psnr=19.3]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00183, loss_moi=0.00496, total_loss=0.00679, train_psnr=19.3]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00183, loss_moi=0.00496, total_loss=0.00679, train_psnr=19.3]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00183, loss_moi=0.00486, total_loss=0.00669, train_psnr=19.4]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00192, loss_moi=0.00479, total_loss=0.00671, train_psnr=19.4]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00199, loss_moi=0.00471, total_loss=0.00669, train_psnr=19.4]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00201, loss_moi=0.00467, total_loss=0.00668, train_psnr=19.4]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.002, loss_moi=0.00459, total_loss=0.00659, train_psnr=19.4]      Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00196, loss_moi=0.00457, total_loss=0.00653, train_psnr=19.4]    Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00193, loss_moi=0.00488, total_loss=0.0068, train_psnr=19.3]     Epoch 1:  60%|██████    | 3/5 [00:01<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.0019, loss_moi=0.00479, total_loss=0.00668, train_psnr=19.4]    Epoch 1:  60%|██████    | 3/5 [00:02<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00187, loss_moi=0.00487, total_loss=0.00673, train_psnr=19.3]    Epoch 1:  60%|██████    | 3/5 [00:02<00:01,  1.89it/s, eval_psnr=23.5, loss_mc=0.00185, loss_moi=0.00482, total_loss=0.00667, train_psnr=19.3]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00185, loss_moi=0.00482, total_loss=0.00667, train_psnr=19.3]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00185, loss_moi=0.00482, total_loss=0.00667, train_psnr=19.3]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00184, loss_moi=0.00485, total_loss=0.0067, train_psnr=19.3]     Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00182, loss_moi=0.00481, total_loss=0.00663, train_psnr=19.3]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00186, loss_moi=0.00483, total_loss=0.0067, train_psnr=19.3]     Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00205, loss_moi=0.00489, total_loss=0.00693, train_psnr=19.2]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00202, loss_moi=0.00498, total_loss=0.00699, train_psnr=19.2]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00203, loss_moi=0.00493, total_loss=0.00696, train_psnr=19.2]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00204, loss_moi=0.0049, total_loss=0.00694, train_psnr=19.2]     Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00203, loss_moi=0.00488, total_loss=0.0069, train_psnr=19.2]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00201, loss_moi=0.00484, total_loss=0.00685, train_psnr=19.3]    Epoch 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00201, loss_moi=0.00478, total_loss=0.00679, train_psnr=19.3]    Epoch 1: 100%|██████████| 5/5 [00:02<00:00,  1.91it/s, eval_psnr=23.5, loss_mc=0.00201, loss_moi=0.00478, total_loss=0.00679, train_psnr=19.3]    Epoch 1: 100%|██████████| 5/5 [00:02<00:00,  1.90it/s, eval_psnr=23.5, loss_mc=0.00201, loss_moi=0.00478, total_loss=0.00679, train_psnr=19.3]

    ArtifactRemoval(
      (backbone_net): UNet(
        (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (Conv1): Sequential(
          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Conv2): Sequential(
          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Conv3): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Up3): Sequential(
          (0): Upsample(scale_factor=2.0, mode='nearest')
          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
        (Up_conv3): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Up2): Sequential(
          (0): Upsample(scale_factor=2.0, mode='nearest')
          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
        (Up_conv2): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 198-202

Test the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 202-216

.. code-block:: Python


    plot_images = True
    method = "multioperator_imaging"

    test(
        model=model,
        test_dataloader=test_dataloader,
        physics=physics,
        device=device,
        plot_images=plot_images,
        save_folder=RESULTS_DIR / method / operation,
        verbose=verbose,
        wandb_vis=wandb_vis,
    )



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_001.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_002.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_003.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_003.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_004.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_004.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_005.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_multioperator_imaging_005.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Processing data of operator 1 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:01<00:00,  1.09s/it]    100%|██████████| 1/1 [00:01<00:00,  1.09s/it]
    Processing data of operator 2 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:01<00:00,  1.12s/it]    100%|██████████| 1/1 [00:01<00:00,  1.12s/it]
    Processing data of operator 3 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:01<00:00,  1.10s/it]    100%|██████████| 1/1 [00:01<00:00,  1.10s/it]
    Processing data of operator 4 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:01<00:00,  1.08s/it]    100%|██████████| 1/1 [00:01<00:00,  1.08s/it]
    Processing data of operator 5 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:01<00:00,  1.08s/it]    100%|██████████| 1/1 [00:01<00:00,  1.08s/it]
    Processing data of operator 6 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 88.37it/s]
    Processing data of operator 7 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 96.82it/s]
    Processing data of operator 8 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 97.17it/s]
    Processing data of operator 9 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 98.08it/s]
    Processing data of operator 10 out of 10
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 99.57it/s]
    Test PSNR: No learning rec.: 13.10+-1.74 dB | Model: 20.05+-1.55 dB. 

    (20.050799751281737, 1.5485068673773368, 13.103665447235107, 1.7379694923885824)




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 9.136 seconds)


.. _sphx_glr_download_auto_examples_self-supervised-learning_demo_multioperator_imaging.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_multioperator_imaging.ipynb <demo_multioperator_imaging.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_multioperator_imaging.py <demo_multioperator_imaging.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
